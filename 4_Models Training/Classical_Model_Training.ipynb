{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d819dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0574cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Final_text', 'Category'], dtype='object')\n",
      "X_train shape : (24006,) \n",
      "X_test shape : (6002,)\n"
     ]
    }
   ],
   "source": [
    "df_start = pd.read_csv('preprocessed_df.csv').drop(columns=['Unnamed: 0'])\n",
    "print(df_start.columns)\n",
    "\n",
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_start[\"Final_text\"],df_start[\"Category\"],test_size=0.2,shuffle=True)\n",
    "print(\"X_train shape : {} \\nX_test shape : {}\".format(X_train.shape , X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7210c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a934f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194c27e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art       0.99      0.99      0.99      2007\n",
      "     Economy       0.99      0.99      0.99      1950\n",
      "       Sport       0.99      1.00      0.99      2045\n",
      "\n",
      "    accuracy                           0.99      6002\n",
      "   macro avg       0.99      0.99      0.99      6002\n",
      "weighted avg       0.99      0.99      0.99      6002\n",
      "\n",
      "Confusion Matrix : \n",
      " [[1983   16    8]\n",
      " [  10 1934    6]\n",
      " [   3    6 2036]]\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10)\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)\n",
    "\n",
    "#classification_report\n",
    "print(classification_report(y_test , y_predict))\n",
    "print('Confusion Matrix : \\n' , confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8219b257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art       0.99      0.99      0.99      2007\n",
      "     Economy       0.99      0.99      0.99      1950\n",
      "       Sport       0.99      0.99      0.99      2045\n",
      "\n",
      "    accuracy                           0.99      6002\n",
      "   macro avg       0.99      0.99      0.99      6002\n",
      "weighted avg       0.99      0.99      0.99      6002\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1981   14   12]\n",
      " [  17 1927    6]\n",
      " [   5   14 2026]]\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = nb_tfidf.predict(X_test_vectors_tfidf)\n",
    "\n",
    "#classification_report\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8234512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preddicted Category is : Art\n",
      "Category Labeles is    :      Art      Economy     Sports\n",
      "Category Probilties is : [[0.98761557 0.00133588 0.01104856]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Art'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the input data \n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "WordNetLemmatiz = WordNetLemmatizer()\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punc_free = \"\".join(i for i in text if i not in punctuation)\n",
    "    return punc_free\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_free = [i for i in text if i not in stopwords]\n",
    "    return stop_free\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [WordNetLemmatiz.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "\n",
    "# preporcessing new text input\n",
    "def all_processing(text):\n",
    "    \n",
    "    punc = remove_punctuation(text)\n",
    "    low = punc.lower()\n",
    "    words = word_tokenize(low)\n",
    "    stop_free = \" \".join(remove_stopwords(words))\n",
    "    lemm_text = \"\".join(lemmatizer(stop_free))\n",
    "    vectors = tfidf_vectorizer.transform([lemm_text])\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "test_input = all_processing(\"Love, Anger and Song: Remembering Youssef Chahine, Egypt's most eminent filmmaker\")\n",
    "\n",
    "input_predict = lr_tfidf.predict(test_input)\n",
    "input_proba = lr_tfidf.predict_proba(test_input)\n",
    "\n",
    "print(\"preddicted Category is :\" , (input_predict[0]))\n",
    "print(\"Category Labeles is    :      Art      Economy     Sports\")\n",
    "print(\"Category Probilties is :\" , (input_proba))\n",
    "\n",
    "labels = [\"Art\",\"Economy\",\"Sports\"]\n",
    "labels[np.argmax(input_proba)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c620f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
